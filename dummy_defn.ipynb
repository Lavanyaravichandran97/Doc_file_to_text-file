{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488e186c-c08a-4721-8199-f599f392e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import docx2txt\n",
    "import re\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b53c9c0a-a10b-45d7-83fd-d920bf5e5a07",
   "metadata": {},
   "source": [
    "filepath = '‪C:/ML Training Docs/New folder/dummy_file/dummy.docx'\n",
    "content = ''\n",
    "filepath=filepath.lstrip('\\u202a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6687644-a880-40b9-b11d-090dba22831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'‪...\\New folder\\dummy_file\\dummy.docx'\n",
    "content = ''\n",
    "if filepath.startswith(\"\\u202a\"):\n",
    "    filepath=filepath.lstrip('\\u202a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d177f205-2326-471c-8129-d0645c15aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docx_to_txt(path):\n",
    "#     f=os.listdir(path)\n",
    "#     n=os.listdir(path)\n",
    "#     name=[i[:-5] for i in n if i.endswith('.docx')]\n",
    "#     file=[i for i in f if i.endswith('docx')]\n",
    "#     for i,j in zip(file,name):\n",
    "        # Passing docx file to process function\n",
    "    text = docx2txt.process(path)\n",
    "    return text\n",
    "#     content =text\n",
    "#     print(text)\n",
    "#         with open(des+\"%s.txt\"+%j, \"w\",encoding=\"utf-8\") as text_file:\n",
    "#             print(text, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30c0c95-3176-43b0-818c-71d4f01042ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_cleansing(content):\n",
    "    # content =   docx_to_txt(filepath)\n",
    "    # # documents = []\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    # for sen in range(0, len(content)):\n",
    "\n",
    "    #Remove \\n from text\n",
    "\n",
    "    document = re.sub(r'\\\\n', ' ', str(content))\n",
    "    # print(content)\n",
    "    # print(document)\n",
    "\n",
    "    # remove \\t from text\n",
    "    document = re.sub(r'\\\\t', ' ', document)\n",
    "\n",
    "    # Remove \\\\ from the text\n",
    "    document = re.sub(r'\\\\', ' ', document)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "\n",
    "    #Remove special character\n",
    "    document = re.sub(r\"[^a-zA-Z0-9]+\", ' ', document)\n",
    "\n",
    "    # print(document)\n",
    "\n",
    "\n",
    "    # Remove one char joins with 2 digit number\n",
    "    document= re.sub(r'[A-Za-z]{1}[0-9]{2}', ' ', document)\n",
    "    #Remove 1 digit number joins with 2 char\n",
    "    document = re.sub(r'[0-9]{1}[A-Za-z]{2}',' ',document)\n",
    "    #Remove one char in between two numbers\n",
    "    document = re.sub(r'[0-9]{1}[A-Za-z]{1}[0-9]{1}',' ',document)\n",
    "    #Remove one number in between two char\n",
    "    document = re.sub(r'[A-Za-z]{1}[0-9]{1}[A-Za-z]{1}',' ',document)\n",
    "\n",
    "    # Remove two char joins with 2 digit number\n",
    "    document= re.sub(r'[A-Za-z]{2}[0-9]{2}', ' ', document)\n",
    "\n",
    "    # Remove two char joins with 1 digit number\n",
    "    document= re.sub(r'[A-Za-z]{2}[0-9]{1}', ' ', document)\n",
    "    # print(document)\n",
    "\n",
    "\n",
    "    # Remove double digit number\n",
    "    document=re.sub('(\\\\b[0-9][0-9] \\\\b|\\\\b [0-9][0-9]\\\\b)', ' ', document).strip()\n",
    "    #Remove single character\n",
    "    document=re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', ' ', document).strip()\n",
    "    # Remove single digit number\n",
    "    document=re.sub('(\\\\b[0-9] \\\\b|\\\\b [0-9]\\\\b)', ' ', document).strip()\n",
    "    # print(document)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r' +', ' ', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    #     document = ' '.join(e for e in document if e.isalnum())\n",
    "    document = ' '.join([word for word in document.split(' ') if word not in stop_words])\n",
    "    document = ' '.join([w for w in document.split() if len(w)>1])\n",
    "    return document\n",
    "    \n",
    "#     documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece91098-9ccf-40c5-aaf1-8c217853cd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "dear john mdu member dr sergio 1128329 gmc investigation please find attached invoice unpaid bill chargable pay interest ref ref invoice date invoice limited insures limited invoice bill chargable payment need liability pay amount due date bill settled gmc investigation please find attached invoice unpaid bill chargable pay interest ref ref invoice date invoice limited insures limited pay amount due date attendance note first draft lengthy letter gmc amending letter gmc letter gmc email shen tisdale dr iqbal email dr iqbal text message dr iqbal text message khalid iqbal text message dr iqbal khalid iqbal amending letter gmc sending email dr iqbal khalid iqbal amends letter preparing enclosure letter gmc bill number 23565 matter gmc cost date description amount vat conversation dr iqbal gmc submission amending finalising gmc submission email dr tisdale letter gmc enclosure email gmc att note many lengthy att note bin payable within day wo reserve right charge interest overdue amount regulated solicilors regulation authority full list partner available ai office jso rt london manchester nowcastlo\n"
     ]
    }
   ],
   "source": [
    "filename, file_extension = os.path.splitext(filepath)\n",
    "# print(file_extension)\n",
    "if file_extension == '.docx':\n",
    "    print('hi')\n",
    "    content = docx_to_txt(filepath)\n",
    "    content = data_cleansing(content)\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ca1c02-f39e-427f-810e-2779c7c40214",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=[content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c41c07-26e1-44c2-aa6c-068fb7c61dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_saved=joblib.load(open(r'C:\\ML Training Docs\\New folder\\pickle file\\count_vectorizer_cv.sav','rb'))\n",
    "test_data_features=count_vectorizer_saved.transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc54f0b-f578-4673-804b-73ed59ad4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_saved=joblib.load(open(r'C:\\ML Training Docs\\New folder\\pickle file\\term_freq_inv_df.sav','rb'))\n",
    "test_data_features_tfidf=tfidf_saved.transform(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3abde3bc-577a-4de9-a9ea-8a721776bd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pickled_model=joblib.load(open(r'C:\\ML Training Docs\\New folder\\pickle file\\light_gbm.sav','rb'))\n",
    "lgbm_pickled_model.predict(test_data_features_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
